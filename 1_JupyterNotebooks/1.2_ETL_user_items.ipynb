{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è **ETL (Extract, Transform, Load)**\n",
    "### **üìÇProcesamos el 2do archivo: `user_items.json.gz`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìÇ **user_reviews.json**:: \n",
    "- üóÉÔ∏è `Items `**:** Desanidado: era una lista de diccionarios\n",
    "- üîÑ `Playtime_forever `: Transformamos los minutos a horas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ **EXTRACT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importamos las librer√≠as que vamos a usar**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Pandas se utiliza para el manejo y an√°lisis de datos tabulares\n",
    "import pyarrow as pa  # PyArrow se utiliza para trabajar con formatos de datos columnares y eficientes como Parquet\n",
    "import pyarrow.parquet as pq  # Importamos Parquet\n",
    "\n",
    "import ast  # AST (Abstract Syntax Trees) se utiliza para interpretar expresiones Python\n",
    "import gzip\n",
    "import json  # JSON se utiliza para trabajar con datos en formato JSON\n",
    "import os  # OS proporciona funciones para interactuar con el sistema operativo\n",
    "import time\n",
    "import warnings  # Warnings se utiliza para gestionar advertencias y filtrarlas si es necesario\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from data_utils import data_type_check, duplicados_columna\n",
    "# Autoreload se utiliza para recargar autom√°ticamente los m√≥dulos al realizar cambios\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Descomprimimos el archivo gz** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo descomprimido: ../0 Dataset/users_items.json\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el tiempo de inicio de todo este ipynb \n",
    "start_time = time.time()\n",
    "\n",
    "def descomprimir_archivos_gz(archivos_gz, carpeta_destino):\n",
    "    for archivo_gz in archivos_gz:\n",
    "        with gzip.open(archivo_gz, 'rb') as f_in:\n",
    "            contenido = f_in.read()\n",
    "            archivo_destino = os.path.join(carpeta_destino, os.path.splitext(os.path.basename(archivo_gz))[0])\n",
    "            with open(archivo_destino, 'wb') as f_out:\n",
    "                f_out.write(contenido)\n",
    "        print(f'Archivo descomprimido: {archivo_destino}')\n",
    "\n",
    "# Ejemplo de uso con una lista de archivos gz\n",
    "archivo_gz_a_descomprimir = ['../0 Dataset/users_items.json.gz']\n",
    "carpeta_destino = '../0 Dataset/'\n",
    "\n",
    "descomprimir_archivos_gz(archivo_gz_a_descomprimir, carpeta_destino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üìÇProcesamos el 2do archivo: `user_items.json.gz`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Tomamos los datos del archivo JSON, transformamos en un DataFrame y realizamos una primera observaci√≥n de su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>items_count</th>\n",
       "      <th>steam_id</th>\n",
       "      <th>user_url</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74109</th>\n",
       "      <td>tooditoo</td>\n",
       "      <td>3</td>\n",
       "      <td>76561198081199422</td>\n",
       "      <td>http://steamcommunity.com/id/tooditoo</td>\n",
       "      <td>[{'item_id': '4000', 'item_name': 'Garry's Mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>chocolatemanj</td>\n",
       "      <td>20</td>\n",
       "      <td>76561198067336542</td>\n",
       "      <td>http://steamcommunity.com/id/chocolatemanj</td>\n",
       "      <td>[{'item_id': '240', 'item_name': 'Counter-Stri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  items_count           steam_id  \\\n",
       "74109       tooditoo            3  76561198081199422   \n",
       "2495   chocolatemanj           20  76561198067336542   \n",
       "\n",
       "                                         user_url  \\\n",
       "74109       http://steamcommunity.com/id/tooditoo   \n",
       "2495   http://steamcommunity.com/id/chocolatemanj   \n",
       "\n",
       "                                                   items  \n",
       "74109  [{'item_id': '4000', 'item_name': 'Garry's Mod...  \n",
       "2495   [{'item_id': '240', 'item_name': 'Counter-Stri...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos una lista vac√≠a llamada \"rows\" donde almacenaremos los datos del archivo JSON.\n",
    "rows = []\n",
    "#Abrir el archivo \"user_reviews.json/australian_user_reviews.json\" con la codificaci√≥n MacRoman.\n",
    "with open(\"../0 Dataset/users_items.json\", encoding='utf-8') as f:\n",
    "    # Leer cada l√≠nea del archivo.\n",
    "    for line in f.readlines():\n",
    "        # Utilizar \"ast.literal_eval\" para convertir cada l√≠nea en un diccionario de Python\n",
    "        # y agregarlo a la lista \"rows\".\n",
    "        rows.append(ast.literal_eval(line))\n",
    "\n",
    "#Crear un DataFrame de Pandas a partir de la lista de diccionarios \"rows\".\n",
    "df_users_items = pd.DataFrame(rows)\n",
    "#Veamos unos registros al asar\n",
    "df_users_items.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la funcion personalizada `data_type_check` invocada desde `data_utils.py` podemos observar:\n",
    "- Variables categ√≥ricas\n",
    "- Variables num√©ricas\n",
    "- Dimensiones del dataframe\n",
    "- Nulos\n",
    "- Tipos de datos\n",
    "- Informacion acerca de los datos faltantes o nulos de cada columna    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe 'df_users_items': \n",
      "\n",
      "========================================\n",
      "Dimensiones:  (88310, 5)\n",
      "       columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0      user_id       100.0      0.0            0    object\n",
      "1  items_count       100.0      0.0            0     int64\n",
      "2     steam_id       100.0      0.0            0    object\n",
      "3     user_url       100.0      0.0            0    object\n",
      "4        items       100.0      0.0            0    object\n"
     ]
    }
   ],
   "source": [
    "data_type_check(df_users_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto contiene 5 columnas y 88310 filas sin nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>items_count</th>\n",
       "      <th>steam_id</th>\n",
       "      <th>user_url</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85811</th>\n",
       "      <td>76561198106185045</td>\n",
       "      <td>1</td>\n",
       "      <td>76561198106185045</td>\n",
       "      <td>http://steamcommunity.com/profiles/76561198106...</td>\n",
       "      <td>[{'item_id': '205790', 'item_name': 'Dota 2 Te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id  items_count           steam_id  \\\n",
       "85811  76561198106185045            1  76561198106185045   \n",
       "\n",
       "                                                user_url  \\\n",
       "85811  http://steamcommunity.com/profiles/76561198106...   \n",
       "\n",
       "                                                   items  \n",
       "85811  [{'item_id': '205790', 'item_name': 'Dota 2 Te...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users_items.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÅ **TRANSFORM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columna **'items'** (es una lista de diccionarios)\n",
    "Desanidado de items, que contiene:\n",
    "- Item_name\n",
    "- playtime_forever\n",
    "- playtime_2weeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe 'df_users_items': \n",
      "\n",
      "========================================\n",
      "Dimensiones:  (5170015, 8)\n",
      "            columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0           user_id      100.00     0.00            0    object\n",
      "1       items_count      100.00     0.00            0     int64\n",
      "2          steam_id      100.00     0.00            0    object\n",
      "3          user_url      100.00     0.00            0    object\n",
      "4           item_id       99.67     0.33        16806    object\n",
      "5         item_name       99.67     0.33        16806    object\n",
      "6  playtime_forever       99.67     0.33        16806   float64\n",
      "7   playtime_2weeks       99.67     0.33        16806   float64\n"
     ]
    }
   ],
   "source": [
    "#Creamos una nueva fila para cada elemento de la lista en la columna items\n",
    "df_users_items = df_users_items.explode(\"items\").reset_index()\n",
    "#Eliminamos la columna index\n",
    "df_users_items = df_users_items.drop(columns=\"index\")\n",
    "# Creamos una nueva columna para cada elemento de la lista en la columna items\n",
    "df_users_items = pd.concat([df_users_items, pd.json_normalize(df_users_items['items'])], axis=1)\n",
    "#Una vez extraidos eliminamos la columna items\n",
    "df_users_items.drop(columns=['items'], inplace=True)\n",
    "\n",
    "data_type_check(df_users_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playtime_forever: Transformamos los minutos a horas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes de limpiar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          6.0\n",
       "1          0.0\n",
       "2          7.0\n",
       "3          0.0\n",
       "4          0.0\n",
       "          ... \n",
       "5170010    0.0\n",
       "5170011    3.0\n",
       "5170012    4.0\n",
       "5170013    3.0\n",
       "5170014    NaN\n",
       "Name: playtime_forever, Length: 5170015, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostramos un playtime_forever de ejemplo\n",
    "print(\"Antes de limpiar\")\n",
    "df_users_items['playtime_forever']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despues de limpiar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0           0.100000\n",
       "2           0.116667\n",
       "8          78.883333\n",
       "9          30.883333\n",
       "10          5.550000\n",
       "             ...    \n",
       "5170008     0.716667\n",
       "5170011     0.050000\n",
       "5170012     0.066667\n",
       "5170013     0.050000\n",
       "5170014     0.000000\n",
       "Name: playtime_forever, Length: 3302052, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#borramos donde no haya tiempo de juego\n",
    "df_users_items = df_users_items[df_users_items['playtime_forever'] != 0]\n",
    "#Convertimos los minutos a horas\n",
    "df_users_items['playtime_forever'] = df_users_items['playtime_forever'] / 60\n",
    "\n",
    "df_users_items['playtime_forever'].fillna(0, inplace=True)\n",
    "\n",
    "# mostramos un playtime_forever de ejemplo\n",
    "print(\"Despues de limpiar\")\n",
    "df_users_items['playtime_forever']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya tenemos la informacion de tiempo de juego acumulado por usuario, borramos esta columna innecesaria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_items = df_users_items.drop('playtime_2weeks', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### item_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_items['item_name'].fillna(0, inplace=True)\n",
    "df_users_items['item_name'] = df_users_items['item_name'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### steam_id y user_url\n",
    "- Eliminamos las columnas irrelevantes que no nos riven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_items.drop([\"user_url\",\"steam_id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminar espacios en blanco al principio y al final de los valores\n",
    "df_users_items['user_id'] = df_users_items['user_id'].str.strip()\n",
    "# Llenar valores nulos con un valor espec√≠fico (por ejemplo, cadena vac√≠a)\n",
    "df_users_items['user_id'].fillna(' ', inplace=True)\n",
    "# Eliminar caracteres especiales o no imprimibles\n",
    "df_users_items['user_id'] = df_users_items['user_id'].str.replace(r'\\W', '')\n",
    "# Convertir a tipo string\n",
    "df_users_items = df_users_items.astype({'user_id': 'string'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **item_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe 'df_users_items': \n",
      "\n",
      "========================================\n",
      "Dimensiones:  (3263076, 5)\n",
      "            columna  %_no_nulos  %_nulos  total_nulos       tipo_dato\n",
      "0           user_id       100.0      0.0            0  string[python]\n",
      "1       items_count       100.0      0.0            0           int64\n",
      "2           item_id       100.0      0.0            0           int32\n",
      "3         item_name       100.0      0.0            0          object\n",
      "4  playtime_forever       100.0      0.0            0         float64\n"
     ]
    }
   ],
   "source": [
    "df_users_items['item_id'].fillna(0, inplace=True)\n",
    "df_users_items = df_users_items.drop_duplicates(keep='first')\n",
    "df_users_items['item_id'] = df_users_items['item_id'].astype(int)\n",
    "\n",
    "data_type_check(df_users_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì§ **LOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la ruta del archivo Parquet\n",
    "ruta_parquet = os.path.abspath('../0 Dataset/1.2_user_items_LISTO.parquet')\n",
    "\n",
    "# Convertir el DataFrame de pandas a una tabla de PyArrow\n",
    "df_users_items = pa.Table.from_pandas(df_users_items)\n",
    "# Escribir la tabla en un archivo Parquet\n",
    "pq.write_table(df_users_items, ruta_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos el archivo descomprimidos que ahora tenemos limpio y liviano en formato parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo eliminado: ../0 Dataset/users_items.json\n"
     ]
    }
   ],
   "source": [
    "# Lista de archivos descomprimidos\n",
    "gz_descomprimidos = [\n",
    "    '../0 Dataset/users_items.json'\n",
    "]\n",
    "\n",
    "# Eliminar archivos descomprimidos\n",
    "for archivo_json in gz_descomprimidos:\n",
    "    try:\n",
    "        os.remove(archivo_json)\n",
    "        print(f'Archivo eliminado: {archivo_json}')\n",
    "    except FileNotFoundError:\n",
    "        print(f'Archivo no encontrado: {archivo_json}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos el tiempo de ejecucion total de nuestro proceso ETL üî•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de ejecuci√≥n de este ipynb: 3.42 minutos\n"
     ]
    }
   ],
   "source": [
    "# Obtener el tiempo de finalizaci√≥n\n",
    "end_time = time.time()\n",
    "# Calcular el tiempo total de ejecuci√≥n\n",
    "total_time = end_time - start_time\n",
    "# Convertir a minutos y redondear a 2 decimales\n",
    "total_time_minutes = round(total_time / 60, 2)\n",
    "# Imprimir resultados\n",
    "print(f\"Tiempo total de ejecuci√≥n de este ipynb: {total_time_minutes} minutos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
